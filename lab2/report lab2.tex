\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{language=C,
	numbers=left,
	stepnumber=1,    
	firstnumber=1,
	numberfirstline=true
	aboveskip=5mm,
	belowskip=5mm,
	showstringspaces=false,
	columns=flexible,
	basicstyle={\small\ttfamily},
	numberstyle=\tiny\color{gray},
	keywordstyle=\color{blue},
	commentstyle=\color{dkgreen},
	stringstyle=\color{mauve},
	breaklines=true,
	breakatwhitespace=true
	tabsize=3
}

\title{Artificial Intelligence 1 \\ Lab 2}%Update the lab (assignment number)
\author{Roeland Lindhout (s2954524) \& Younes Moustaghfir (s2909758) \\ AI2/AI3} %Change the names and fill in the student numbers and the group name (AI1/AI2/CS1 etc)
\date{\today}%Update the date

\begin{document}
	
	\maketitle
	
	\section{N-queens problem}
	
	The problem at hand is about the n-queens problem. It is an expansion of the 8-queens problem, which has often been discussed in previous courses. The goal is to place "n" number of queens on an n*n sized board, in such a way that they are not able to hit each other. For sizes bigger than 4, more solutions are possible.
	
	The way to solve such a problem can be done in various ways. One approach, is to randomly place queens on the board until they accidentally have one of the right configurations. Obviously, this can be done more effectively. The first way we try to solve this, is by the hill-climbing approach. This basically means, that for every row, we look at which position is better than the previous position, and then choose that one. Still a blunt way to solve the problem, but already more sophisticated than randomly trying. The problem with this, is that it often gets stuck in local maxima. The second approach, is by simulated annealing. Simulated annealing is similar to hill-climbing, but it includes random moves, to avoid the problem with the local maxima. The way you decide when to make a random jump, is based on a relationship between the "temperature" (in this case, the number of correct queens) and the elapsed time. As the time increases, less random jumps are made. The final approach is with a generic algorithm. A genetic algorithm works much more differently. First of all, it does not use an initial state, but an initial population. This initial population is then sorted on their "fitness", which is the number of correctly placed queens. The best few are allowed to reproduce, i.e. make new states. This is done by combining two states. There is also a small chance of a random mutation in the newly produced state. By mixing up the parents and including the mutations, the population will approach the solution state, until one of the children is the correct solution.
		
	\subsection{Hill Climbing algorithm}
	We will be solving this problem using three different algorithms. First, we will use Hill Climbing to solve this. This is a quite straightforward algorithm. If, in your search space, the neighbour has a higher value, go to that neighbour and repeat that process until you've found a maximum. In the case of the n-queens problem, you look at all the positions in a column and select the one with the highest value.
	
	For this algorithm, we look at each neighbouring state of the current column. We then evaluate each position that the queen can go to. We do that for each queen and then move that queen to the position with the highest evaluation.
	
	This approach is quite simple and therefore not that effective. The algorithm will not always find a solution. For the unmodified code, 6 out of 20 times in average, the algorithm was able to find a solution. We've therefore tried some improvements for the code. Hill Climbing can get stuck in local optima and then it's unable to find the global optimum. We therefore implemented something that when the algorithm is stuck, it chooses a random queen to randomly move so that is might get out of this local optimum. With this improvement, we see its success rate in Table 1. This table is in the Appendix

	This algorithm does quite well up to 7 queens, after that it's performance declines. The modified code did better than the original code.
	


	
	\subsection{Simulated Annealing algorithm}
	Simulated Annealing is somewhat the same as Hill Climbing, but better. Hill Climbing is able to get stuck in local maxima, therefore not always returning the optimal solution. Simulated Annealing allows "bad moves". With these "bad moves", it is able to escape local maxima and find a global maximum. 
	
	For Simulated Annealing, we figuered that the temperature function should be something like: $ T(t) = (initial)T * t$, where we filled in 50 for the starting temperature and t should be something around $0.99$. We have used this function to lower the temperature until it has reached a certain value, in our case: $0.001$. This sets the maximum amount of iterations, because if the temperature drops below that certain value, the while loop of our program stops. With these values, SA is quite similar to Hill Climbing. The difference is that we have implemented a function $ExpMove()$ that decides whether a "bad move" should be made. This is where we differ from the pseudocode as well. We look at a current position and the maximum of a column to decide whether a bad move is accepted.
	
	For simulated Annealing, we have noticed a few things. First of all, the algorithm usually finds a solution within 50 steps. When it did not find a solution after 50 steps, its chance of finding one is very small. As might have been clear by the previous sentence, the program does not always find a solution. For a number of queens above 10 this only gets worse. Why does it get worse? For more than 10 queens, the search space gets too big for our algorithm and the "bad move" that the algorithm takes will help the algorithm. We've played around with different temperatures and they don't seem to matter that much. As long as the temperature is not too low, the program does find a solution sometimes. If the problem is small, a lower temperature is needed. If the problem size increases, you might have to increase the temperature. The program, for some reason, does not always find a solution. For a size bigger than 10, the program gets to the point were is does not find a solution at all after some tries. 
	
	
	\subsection{Genetic algorithm}
	
	The genetic algorithm consists of three functions. The first function describes the mutation. The mutation is as random as possible. It takes a random queen, and places this at a random, new position, similar to how the random-search algorithm was implemented. Next, there is a function to sort the population. The population is sorted based on the evaluateState function from the given program. This evaluation is stored on the last place in the array. For every item in the array, the evaluation is compared to the evaluation of the next one, and then shifted until they are all in the right place. The next function is the real implementation of the program. First, a 2D array is made, with a size of the number of queens to the power of 2. This is chosen, because the number of different places the queens can stand, also increases exponentially. The first dimension represents the population, the second represents the configuration of the separate parents. The parents are initially randomly produced. After this, the population is sorted and the crossover can begin. The crossover is done with the best 20 \% of the population. This was chosen to keep a fairly large amount of different configurations, but not too much. The crossover is done in pairs, so the first of the population pairs with the second, the third with the fourth and so forth. A random number between 0 and the number of queens is chosen. The first parent gives it's rows up to and including this number, and the second parent starting from this number. In this way, the child is a crossover between the parents. The child is placed at the last place in the population, thereby replacing the worst of the population. Then, 4 \% of the children receive a mutation. This seems like a high number, but we thought it was necessary, because the initial population is randomly produced, and therefore it is quite possible that there are position that are not included in any of the parents, and we try to include these positions in the population by these mutations. Then, the population is once again sorted, and the process continues until the solution is found. The population is immediately sorted after the child is made, so the process is sped up, if the child is better than the first 20 \%. Finally, the final state is printed.
	
	The program is very fast for problems up to 8. It is also able to solve problems with 8 and 9 queens, but this can take quite long. It does always find a solution. It all depends on the random initialization of the population. If this is done very unfortunately, it takes longer. Problems bigger than 9, have not found a solution yet. We tried a problem with 10 queens, but after 15 minutes we gave up, expecting it not to find a solution ever. The valgrind output is the following for n = 8 :
		\begin{lstlisting}
		Number of queens (1<=nqueens<100): 8
		Algorithm: (1) Random search  (2) Hill climbing  (3) Simulated Annealing  (4) Genetic algorithm: 4
		Final state is
		....q...
		......q.
		.q......
		...q....
		.......q
		q.......
		..q.....
		.....q..
		==26906== 
		==26906== HEAP SUMMARY:
		==26906==     in use at exit: 0 bytes in 0 blocks
		==26906==   total heap usage: 65 allocs, 65 frees, 2,816 bytes allocated
		==26906== 
		==26906== All heap blocks were freed -- no leaks are possible
		==26906== 
		==26906== For counts of detected and suppressed errors, rerun with: -v
		==26906== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
		
		\end{lstlisting}
		
	
	\section{Nim}
	
	The game of Nim is about a stack of items, from which each player can take 1 to 3 items each turn, after which the other player's turn is. You lose when you have to take the last item. The players in our program are thought to be playing optimally. Playing optimally means that in each situation, the best possible choice is made, based on the best possible choice in the next turn of the opponent. Doing this, it can quickly be predicted who wins. For n=3, MAX, who begins, will take 2, leaving only 1 for MIN, who then loses. For n=4, MAX will take 3, once again leaving only one for MIN, who will once again lose. For n=5, assuming optimal play, MIN will win. First, MAX will take 3, and then MIN will take 1, leaving only 1 for MAX to take. No matter what MAX does at his/her first turn, MIN will be able to do a finishing move. For n=6, MAX will win. MAX will start by taking 1 item, which will result in the same situation as discussed before this one, only from the perspective of MIN.
	
	\subsection{Program description and evaluation}
	
	The program is fairly simple. We kept the basic structure of the given program, but we placed everything into one function. First, it is checked if the state is one. In this case, MAX has lost, and therefore -1 is returned. If this is not the case, the different moves are evaluated. Each move is recursively passed onto the function again, only negated, to show that it is MIN's turn. This is assigned to a variable. If this is variable is better than best, this variable becomes the new best. Initially, best was set to -$\infty$. The move that was the best, is stored in the variable bestmove. This is printed at the end. At this point, all moves have been decided, and printed at once. This function is used the same way as in the original program, with the only change that it does not use the variable turn.
	
	The program always find a solution, but somehow not always the most optimal solution, from MAX's point of view. The more items there are at the beginning, the longer it takes to find an answer. Up to $\pm$ 35, the time it takes is not too long, but after this, the program becomes very slow. 
	
	When we run the program with 10, 20, 30, 40 and 50, we see a clear pattern occurring. The program switches between choosing 1 and 3 matches to take of the pile. Min always loses in those cases. If a transposition table was made, this could easily be stored in there. In certain states, it quite clear which move to make, but it might still cost a lot of computational resources. For 50 matches, it takes quite some time to calculate each state and choose the correct one. Transposition tables help the program to become faster. We were not able to insert a transposition table into our program.
	
	
	\section{Source code}
	
	\lstinputlisting[caption = \tt nqueens.c]{queens/nqueens.c}
	\lstinputlisting[caption = \tt nim.c]{nim/nim.c}
	
	\section{Appendix}
\begin{table}[H]
\centering
\caption{Succes rate of modified algorithm}
\label{my-label}
\begin{tabular}{ll}
Number of Queens & Succesrate \\
4                & 100\%      \\
5                & 100\%      \\
6                & 100\%      \\
7                & 100\%      \\
8                & 50\%       \\
9                & 35\%       \\
10               & 20\%       \\
11               & 20\%       \\
12               & 10\%       \\
13               & 5\%       
\end{tabular}
\end{table}
		
\end{document}